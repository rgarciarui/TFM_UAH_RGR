# -*- coding: utf-8 -*-
"""TFM UAH Master Ciencia Datos [Ricardo Garcia Ruiz] v. 2.0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16WB56s0hFwtzIVH0piidJMvQwf-eEzK6

# **Trabajo final Master Ciencia de Datos**

Autor: **Ricardo García Ruiz**

Universidad Alcalá de Henares
Fecha: 12/01/2020
---

# **Objetivo general del trabajo**

El reconocimiento de objetos en imágenes es un tema apasionante que se encuentra en primera línea de trabajo tanto desde el punto de vista de la investigación académica como desde el punto de vista de la innovación tecnológica. Dentro de este área, una de las más complejas técnicas de reconocimiento se encuentra en la restauración de imágenes dañadas.

Aplicando técnicas de Deep Learning, mediante redes neuronales, convolucionales, u otras técnicas se han desarrollado métodos de reconocimiento facial tan eficientes como los que podemos ver en algunos dispositivos móviles. 
En este trabajo se aplicarán estas novedosas técnicas dirigiéndolas al estudio y caracterización de imágenes de moda. Este campo resulta ser uno en el que no se ha desarrollado eficientemente estas técnicas de reconocimiento y restauración de objetos imágenes y creemos que puede ser un excelente campo de aplicación práctica desde el punto de vista de la innovación.

Se emplean técnicas de redes neuronales, modelos convolucionales, que se aplican en un piloto a un dataset de Fashion Week, un conjunto de datos de la moda más relevante y uno los eventos más importantes de la moda actual.
Los resultados nos permiten reconocer objetos determinados dentro de las imágenes y, en definitiva, clasificar las imágenes en función del reconocimiento de los objetos y de su nivel de daño antes de la restauración, sin necesidad de tener una referencia de clase preestablecida para cada imagen.
Entendemos que estos resultados van a ser muy importantes en los aspectos de innovación sostenible en procesos de tratamiento de imágenes en el ámbito de la moda. Estos procesos de innovación creemos que pueden desarrollarse novedosas aplicaciones comerciales derivadas de los resultados de esta investigación y tener un alto impacto en los resultados de comercialización.

# **Verificación de la máquina, código y datos**

Se va a utilizar un notebook de Jupyter subido a la plataforma Google Collab. De esta forma se independiza el resultado y tiempo de proceso de los condicionantes de la máquina instalada en un ordenardor personal o sobremesa.

El notebook tendrá las siguientes características:

*   Utilizará Python 3
*   El notebook utilizará un entorno de ejecución con GPU
*   Utilizará las librerías **Torch**

A continuación se verifican las instalaciones correctas de cada requerimiento.

## ***Verificación de contexto***
"""

# Se verifica la instalación de CUDA y Python 3
! nvcc --version
! python --version

import torch
print(torch.cuda.get_device_name(0))
print(torch.__version__)

import warnings
warnings.filterwarnings("ignore")

"""## ***Lectura de código y datos desde GitHub para el procesado de Inpainting***"""

!pip install torchviz

# Se descargan los datos clonando desde 
! git clone https://github.com/rgarciarui/TFM_UAH_RGR.git

#from google.colab import files
#uploaded = files.upload()

"""# **Restauración**

## **Carga de las librerías de uso en la prueba**
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import print_function
import matplotlib.pyplot as plt
import matplotlib as mpl
# %matplotlib inline

import os
import numpy as np
from TFM_UAH_RGR.models.resnet import ResNet
from TFM_UAH_RGR.models.unet import UNet
from TFM_UAH_RGR.models.skip import skip
from TFM_UAH_RGR.models import get_net

# Se importan las librerias de torch
import torch
import torch.optim
from skimage.measure import compare_psnr

# Librerias de utilizadas para inpainting
from TFM_UAH_RGR.utils.inpainting_utils import *

# Visualización de modelos
from TFM_UAH_RGR.utils.common_utils import torch_summarize

torch.backends.cudnn.enabled = True
torch.backends.cudnn.benchmark = True

PLOT = True
imagesize = -1
dim_div_by = 64
dtype = torch.cuda.FloatTensor

inline_rc = dict(mpl.rcParams)

"""## ***Prueba con imágenes en color***

En este punto generamos una prueba con una imagen en colar.

Para ello generamos una mascara noise que fusionamos con la imagen original para distorsionarla.

En el resultado mostramos la imagen original, la mascara y la mezcla de imagen y mascara.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Cargamos imágenes del conjunto de dataset, en 'data' para trabajar
# colourFiles = ['./TFM_UAH_RGR/data/restoration/10 - Bicycle.png',
#                './TFM_UAH_RGR/data/restoration/11 - kate.png',
#                './TFM_UAH_RGR/data/restoration/12 - Lion.png',
#                './TFM_UAH_RGR/data/restoration/13 - tinajas.png',
#                './TFM_UAH_RGR/data/restoration/14 - Peabody-library.png']
# 
# # selección de la imagen  [0-4]
# image_number = 0
# 
# # leemos la imagen original deseada
# image_pil, image_np = get_image(colourFiles[image_number], imagesize)
# 
# # creamos una mascara PIL
# image_mask = get_bernoulli_mask(image_pil, 0.35)
# 
# # conversion de PIL a matriz numpy
# image_mask_np = pil_to_np(image_mask)
# image_mask_np[1] = image_mask_np[0]
# image_mask_np[2] = image_mask_np[0]
#    
# # Imagen alterada con la mascara
# image_masked = image_np * image_mask_np
# 
# # tensor cuda
# mask_var = np_to_torch(image_mask_np).type(dtype)
# 
# # Mostramos la imagen original, la mascara de ruido y la imagen final con ruido
# plot_image_grid([image_np, image_mask_np, image_masked], 3,11);

show_every=50
figsize=5
pad = 'reflection' # 'zero'
INPUT = 'noise'
input_depth = 32
OPTIMIZER = 'adam'
OPT_OVER =  'net'

# imagen en color
num_iter = 1000
LR = 0.01
reg_noise_std = 0.00

# devuelve un modelo        
net = skip(input_depth, 
               image_np.shape[0], 
               num_channels_down = [16, 32, 64, 128, 128],
               num_channels_up   = [16, 32, 64, 128, 128],
               num_channels_skip =    [0, 0, 0, 0, 0],   
               filter_size_down = 3, filter_size_up = 3, filter_skip_size=1,
               upsample_mode='bilinear', 
               downsample_mode='avg',
               need_sigmoid=True, need_bias=True, pad=pad).type(dtype)

# Perdida
mse = torch.nn.MSELoss().type(dtype)
image_var = np_to_torch(image_np).type(dtype)  # tensor cuda

# tensor cuda
net_input = get_noise(input_depth, INPUT, image_np.shape[1:]).type(dtype).detach()

# Datos del modelo
print(torch_summarize(net))

# Datos del modelo 2
#print(net)  # modelo
#print("Parametros del modelo: ", sum([param.nelement() for param in net.parameters()]) )  # parametros del modelo

from torch import nn
from torchviz import make_dot, make_dot_from_trace

# Visualizacion grafica del modelo
make_dot(net(net_input), params=dict(net.named_parameters()))

def closure():

    global i, psrn_masked_last, last_net, net_input
    
    if reg_noise_std > 0:
        net_input = net_input_saved + (noise.normal_() * reg_noise_std)
    
    out = net(net_input)

    total_loss = mse(out * mask_var, image_var * mask_var)
    total_loss.backward()
    
    psrn_masked = compare_psnr(image_masked, out.detach().cpu().numpy()[0] * image_mask_np) 
    psrn = compare_psnr(image_np, out.detach().cpu().numpy()[0]) 

    print ('Iteracion %05d    Perdida %f PSNR_masked %f PSNR %f' % (i, total_loss.item(), psrn_masked, psrn),'\r', end='')
    print('\n')
    #print(total_loss)
    
    if  PLOT and i % show_every == 0:
        out_np = torch_to_np(out)
        
        # Backtracking
        if psrn_masked - psrn_masked_last < -5: 
            print('Volviendo al punto de control anterior.\n')

            for new_param, net_param in zip(last_net, net.parameters()):
                net_param.data.copy_(new_param.cuda())

            return total_loss*0
        else:
            last_net = [x.cpu() for x in net.parameters()]
            psrn_masked_last = psrn_masked



        plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)

    i += 1

    #print("salida de función con perdida:", (total_loss.cpu()).detach().numpy())
    return total_loss, total_loss.item(), psrn, psrn_masked

"""relación pico señal / ruido (PSNR) = psrn

error cuadrático medio (MSE) = total_loss
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Inicialización de variables globales 
# last_net = None
# psrn_masked_last = 0
# i = 0
# 
# net_input_saved = net_input.detach().clone()
# noise = net_input.detach().clone()
# 
# # Run
# p = get_params(OPT_OVER, net, net_input)
# #total_loss_item_acum, psrn_acum, total_loss_acum = optimize(OPTIMIZER, p, closure, LR=LR, num_iter=num_iter)
# total_loss_final, total_loss_item_final, psrn_final, psrn_masked_final = optimize(OPTIMIZER, p, closure, LR=LR, num_iter=num_iter)

out_np = torch_to_np(net(net_input))
q = plot_image_grid([np.clip(out_np, 0, 1), image_np], factor=13);

#total_loss_item_final, psrn_final, total_loss_final, psrn_masked_final
print("total_loss_item_final: ", "{0:.4f}".format(total_loss_item_final[len(total_loss_item_final)-1]))
print("Relación pico señal / ruido (PSNR): ", "{0:.4f}".format(psrn_final[len(psrn_final)-1]))
print("Relación pico señal / ruido (PSNR) [masked]: ", "{0:.4f}".format(psrn_masked_final[len(psrn_masked_final)-1]))
print("Error cuadrático medio (MSE): ", "{0:.4f}".format(total_loss_final[len(total_loss_final)-1]), "\n")

fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, figsize=(10,10))
mpl.style.use('seaborn')

ax1.set_title('Indice de pérdida total acumulada en cada iteración'.format('seaborn'), color='C0')
ax1.plot(total_loss_item_final, color='C0')

ax2.set_title('Relación pico señal / ruido (PSNR)'.format('seaborn'), color='C1')
ax2.plot(psrn_final, color='C1')

ax3.plot(total_loss_final, color='C2')
ax3.set_title('Error cuadrático medio (MSE)'.format('seaborn'), color='C2')

ax4.set_title('Relación pico señal / ruido (PSNR)[masked]'.format('seaborn'), color='C3')
ax4.plot(psrn_masked_final, color='C3')

plt.tight_layout()
plt.show()
plt.close()

mpl.rcParams.update(inline_rc)

#print(total_loss_final[4900])

"""## ***Prueba con imágenes en blanco y negro***"""

# Cargamos una imagen del conjunto de dataset, en 'data' para trabajar
blackWhiteFiles = ['./TFM_UAH_RGR/data/restoration/00 - barbara.png',
                   './TFM_UAH_RGR/data/restoration/01 - indian.png',
                   './TFM_UAH_RGR/data/restoration/02 - babak.png',
                   './TFM_UAH_RGR/data/restoration/03 - spooky-mansion.png',
                   './TFM_UAH_RGR/data/restoration/04 - madre-migrante.png']

# selección de la imagen  [0-4]
image_number = 4

# leemos la imagen original deseada
image_pil, image_np = get_image(blackWhiteFiles[image_number], imagesize)

# creamos una mascara PIL
image_np = nn.ReflectionPad2d(1)(np_to_torch(image_np))[0].numpy()
image_pil = np_to_pil(image_np)
    
image_mask = get_bernoulli_mask(image_pil, 0.35)
image_mask_np = pil_to_np(image_mask) 

# Imagen alterada con la mascara
image_masked = image_np * image_mask_np

# tensor cuda
mask_var = np_to_torch(image_mask_np).type(dtype)

# Mostramos la imagen original, la mascara de ruido y la imagen final con ruido
plot_image_grid([image_np, image_mask_np, image_masked], 3,11);

show_every=50
figsize=5
pad = 'reflection' # 'zero'
INPUT = 'noise'
input_depth = 32
OPTIMIZER = 'adam'
OPT_OVER =  'net'

# imagen en B/N 
LR = 0.001
num_iter = 1000 # valor original 11000, 6601
reg_noise_std = 0.03

# devuelve un modelo     
NET_TYPE = 'skip'
net = get_net(input_depth, 'skip', pad, n_channels=1,
                  skip_n33d=128, 
                  skip_n33u=128, 
                  skip_n11=4, 
                  num_scales=5,
                  upsample_mode='bilinear').type(dtype)

    
# Perdida
mse = torch.nn.MSELoss().type(dtype)
image_var = np_to_torch(image_np).type(dtype)

# tensor cuda
net_input = get_noise(input_depth, INPUT, image_np.shape[1:]).type(dtype).detach()

# Datos del modelo
print(torch_summarize(net))

from torch import nn
from torchviz import make_dot, make_dot_from_trace

# Visualizacion grafica del modelo
make_dot(net(net_input), params=dict(net.named_parameters()))

def closure():

    global i, psrn_masked_last, last_net, net_input
    
    if reg_noise_std > 0:
        net_input = net_input_saved + (noise.normal_() * reg_noise_std)
    
    out = net(net_input)

    total_loss = mse(out * mask_var, image_var * mask_var)
    total_loss.backward()
    
    psrn_masked = compare_psnr(image_masked, out.detach().cpu().numpy()[0] * image_mask_np) 
    psrn = compare_psnr(image_np, out.detach().cpu().numpy()[0]) 

    print ('Iteracion %05d    Perdida %f PSNR_masked %f PSNR %f' % (i, total_loss.item(), psrn_masked, psrn),'\r', end='')
    print('\n')
    #print(total_loss)
    
    if  PLOT and i % show_every == 0:
        out_np = torch_to_np(out)
        
        # Backtracking
        if psrn_masked - psrn_masked_last < -5: 
            print('Volviendo al punto de control anterior.\n')

            for new_param, net_param in zip(last_net, net.parameters()):
                net_param.data.copy_(new_param.cuda())

            return total_loss*0
        else:
            last_net = [x.cpu() for x in net.parameters()]
            psrn_masked_last = psrn_masked



        plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)

    i += 1

    #print("salida de función con perdida:", (total_loss.cpu()).detach().numpy())
    return total_loss, total_loss.item(), psrn, psrn_masked

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Inicialización de variables globales 
# last_net = None
# psrn_masked_last = 0
# i = 0
# 
# net_input_saved = net_input.detach().clone()
# noise = net_input.detach().clone()
# 
# # Run
# p = get_params(OPT_OVER, net, net_input)
# #total_loss_item_acum, psrn_acum, total_loss_acum = optimize(OPTIMIZER, p, closure, LR=LR, num_iter=num_iter)
# total_loss_final, total_loss_item_final, psrn_final, psrn_masked_final = optimize(OPTIMIZER, p, closure, LR=LR, num_iter=num_iter)

out_np = torch_to_np(net(net_input))
q = plot_image_grid([np.clip(out_np, 0, 1), image_np], factor=13);

#total_loss_item_final, psrn_final, total_loss_final, psrn_masked_final
print("total_loss_item_final: ", "{0:.4f}".format(total_loss_item_final[len(total_loss_item_final)-1]))
print("Relación pico señal / ruido (PSNR): ", "{0:.4f}".format(psrn_final[len(psrn_final)-1]))
print("Relación pico señal / ruido (PSNR) [masked]: ", "{0:.4f}".format(psrn_masked_final[len(psrn_masked_final)-1]))
print("Error cuadrático medio (MSE): ", "{0:.4f}".format(total_loss_final[len(total_loss_final)-1]), "\n")

fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, figsize=(10,10))
mpl.style.use('seaborn')

ax1.set_title('Indice de pérdida total acumulada en cada iteración'.format('seaborn'), color='C0')
ax1.plot(total_loss_item_final, color='C0')

ax2.set_title('Relación pico señal / ruido (PSNR)'.format('seaborn'), color='C1')
ax2.plot(psrn_final, color='C1')

ax3.plot(total_loss_final, color='C2')
ax3.set_title('Error cuadrático medio (MSE)'.format('seaborn'), color='C2')

ax4.set_title('Relación pico señal / ruido (PSNR)[masked]'.format('seaborn'), color='C3')
ax4.plot(psrn_masked_final, color='C3')

plt.tight_layout()
plt.show()
plt.close()

mpl.rcParams.update(inline_rc)

"""# **Inpainting**

## ***Escogiendo la imagen a procesar***
"""

# Cargamos imágenes del conjunto de dataset, en 'data' para trabajar
inpaintingFiles = ['./TFM_UAH_RGR/data/inpainting/indian.png',
                   './TFM_UAH_RGR/data/inpainting/kate.png',
                   './TFM_UAH_RGR/data/inpainting/library.png',
                   './TFM_UAH_RGR/data/inpainting/tinajas.png',
                   './TFM_UAH_RGR/data/inpainting/vase.png']

maskFiles = ['./TFM_UAH_RGR/data/inpainting/indian_mask.png',
             './TFM_UAH_RGR/data/inpainting/kate_mask.png',
             './TFM_UAH_RGR/data/inpainting/library_mask.png',
             './TFM_UAH_RGR/data/inpainting/tinajas_mask.png',
             './TFM_UAH_RGR/data/inpainting/vase_mask.png']

# selección de la imagen  [0-4]
image_number = 4
image_path  = inpaintingFiles[image_number]
mask_path = maskFiles[image_number]

NET_TYPE = 'skip_depth6' # one of skip_depth4|skip_depth2|UNET|ResNet

"""## ***Cargando la mascara***"""

image_pil, image_np = get_image(image_path, imagesize)
image_mask_pil, image_mask_np = get_image(mask_path, imagesize)

"""### ***Centrando el corte objetivo***"""

image_mask_pil = crop_image(image_mask_pil, dim_div_by)
image_pil      = crop_image(image_pil,      dim_div_by)

image_np      = pil_to_np(image_pil)
image_mask_np = pil_to_np(image_mask_pil)

# Imagen alterada con la mascara
image_masked = image_mask_np*image_np

"""### ***Visualizando***"""

image_mask_var = np_to_torch(image_mask_np).type(dtype)

plot_image_grid([image_np, image_mask_np, image_masked], 3,11);

"""## **Inicialización**"""

pad = 'reflection' # 'zero'
OPT_OVER = 'net'
OPTIMIZER = 'adam'

"""Ahora vamos a crear funciones especializadas para trabajar con cada una de las 5 imágenes que estamos comprobando:

1.   'indian.png', se aplica la función imageOne()
2.   'kate.png', se aplica la función imageTwo()
3.   'library.png', se aplica la función imageTree()
4.   'tinajas.png', se aplica la función imageFour()
5.   'vase.png', se aplica la función imageFive()
"""

def imageOne():
    INPUT = 'noise'
    input_depth = 32
    LR = 0.01 
    num_iter = 5501
    param_noise = False
    show_every = 50
    figsize = 5
    reg_noise_std = 0.03
    
    net = skip(input_depth, image_np.shape[0], 
               num_channels_down = [128] * 5,
               num_channels_up =   [128] * 5,
               num_channels_skip =    [128] * 5,  
               filter_size_up = 3, filter_size_down = 3, 
               upsample_mode='nearest', filter_skip_size=1,
               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)
    net = net.type(dtype)
    net_input = get_noise(input_depth, INPUT, image_np.shape[1:]).type(dtype)
    
    return net_input, net, LR, num_iter, param_noise, reg_noise_std, show_every, figsize

def imageTwo():
    INPUT = 'noise'
    input_depth = 32
    LR = 0.01 
    num_iter = 6001
    param_noise = False
    show_every = 50
    figsize = 5
    reg_noise_std = 0.03
    
    net = skip(input_depth, image_np.shape[0], 
               num_channels_down = [128] * 5,
               num_channels_up =   [128] * 5,
               num_channels_skip =    [128] * 5,  
               filter_size_up = 3, filter_size_down = 3, 
               upsample_mode='nearest', filter_skip_size=1,
               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)
    net = net.type(dtype)
    net_input = get_noise(input_depth, INPUT, image_np.shape[1:]).type(dtype)
    
    return net_input, net, LR, num_iter, param_noise, reg_noise_std, show_every, figsize

def imageThree():
    INPUT = 'noise'
    input_depth = 1
    
    num_iter = 3001
    show_every = 50
    figsize = 8
    reg_noise_std = 0.00
    param_noise = True
    
    if 'skip' in NET_TYPE:
        
        depth = int(NET_TYPE[-1])
        net = skip(input_depth, image_np.shape[0], 
               num_channels_down = [16, 32, 64, 128, 128, 128][:depth],
               num_channels_up =   [16, 32, 64, 128, 128, 128][:depth],
               num_channels_skip =    [0, 0, 0, 0, 0, 0][:depth],  
               filter_size_up = 3,filter_size_down = 5,  filter_skip_size=1,
               upsample_mode='nearest', # downsample_mode='avg',
               need1x1_up=False,
               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)
        
        LR = 0.01 
        
    elif NET_TYPE == 'UNET':
        
        net = UNet(num_input_channels=input_depth, num_output_channels=3, 
                   feature_scale=8, more_layers=1, 
                   concat_x=False, upsample_mode='deconv', 
                   pad='zero', norm_layer=torch.nn.InstanceNorm2d, need_sigmoid=True, need_bias=True)
        
        LR = 0.001
        param_noise = False
        
    elif NET_TYPE == 'ResNet':
        
        net = ResNet(input_depth, image_np.shape[0], 8, 32, need_sigmoid=True, act_fun='LeakyReLU')
        
        LR = 0.001
        param_noise = False
        
    else:
        assert False

    net = net.type(dtype)
    net_input = get_noise(input_depth, INPUT, image_np.shape[1:]).type(dtype)
    
    return net_input, net, LR, num_iter, param_noise, reg_noise_std, show_every, figsize

def imageFour():
    INPUT = 'noise'
    input_depth = 32
    LR = 0.01 
    num_iter = 6001 # numero iteraciones original 6001, 7501
    param_noise = False
    show_every = 50
    figsize = 5
    reg_noise_std = 0.03
    
    net = skip(input_depth, image_np.shape[0], 
               num_channels_down = [128] * 5,
               num_channels_up =   [128] * 5,
               num_channels_skip =    [128] * 5,  
               filter_size_up = 3, filter_size_down = 3, 
               upsample_mode='nearest', filter_skip_size=1,
               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)
    net = net.type(dtype)
    net_input = get_noise(input_depth, INPUT, image_np.shape[1:]).type(dtype)
    
    return net_input, net, LR, num_iter, param_noise, reg_noise_std, show_every, figsize

def imageFive():
    INPUT = 'meshgrid'
    input_depth = 2
    LR = 0.01 
    num_iter = 5001
    param_noise = False
    show_every = 50
    figsize = 5
    reg_noise_std = 0.03
    
    net = skip(input_depth, image_np.shape[0], 
               num_channels_down = [128] * 5,
               num_channels_up   = [128] * 5,
               num_channels_skip = [0] * 5,  
               upsample_mode='nearest', filter_skip_size=1, filter_size_up=3, filter_size_down=3,
               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)
    
    net = net.type(dtype)
    net_input = get_noise(input_depth, INPUT, image_np.shape[1:]).type(dtype)
    
    return net_input, net, LR, num_iter, param_noise, reg_noise_std, show_every, figsize

# Definición de la función de selección
switcher = {
        1: imageOne,
        2: imageTwo,
        3: imageThree,
        4: imageFour,
        5: imageFive
}
def imageSelection(argument):
    # Obtenemos la función en función del diccionario del switcher
    func = switcher.get(argument+1, lambda: "Error de seleccion")
    # ejecutamos la funcion
    return func()

# ejecucion de la funcion
net_input, net, LR, num_iter, param_noise, reg_noise_std, show_every, figsize = imageSelection(image_number)

# Calcular numero de parametros
s  = sum(np.prod(list(p.size())) for p in net.parameters())
print ('Numero de parámetros: %d' % s)

# Perdida
mse = torch.nn.MSELoss().type(dtype)

image_var = np_to_torch(image_np).type(dtype)
mask_var = np_to_torch(image_mask_np).type(dtype)

"""## **Procesamiento principal**"""

i = 0
def closureInpainting():
    
    global i #, psrn_masked_last, last_net, net_input
    
    if param_noise:
        for n in [x for x in net.parameters() if len(x.size()) == 4]:
            n = n + n.detach().clone().normal_() * n.std() / 50
    
    net_input = net_input_saved
    if reg_noise_std > 0:
        net_input = net_input_saved + (noise.normal_() * reg_noise_std)
        
        
    out = net(net_input)
   
    total_loss = mse(out * mask_var, image_var * mask_var)
    total_loss.backward()

    psrn_masked = compare_psnr(image_masked, out.detach().cpu().numpy()[0] * image_mask_np) 
    psrn = compare_psnr(image_np, out.detach().cpu().numpy()[0])     
        
    print ('Iteracion %05d    Perdida %f' % (i, total_loss.item()), '\r', end='')
    print('\n')

    if  PLOT and i % show_every == 0:
        out_np = torch_to_np(out)
        plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)
        
    i += 1

    #return total_loss, total_loss.item(), psrn, psrn_masked
    return total_loss, total_loss.item(), psrn, psrn_masked

net_input_saved = net_input.detach().clone()
noise = net_input.detach().clone()

# Datos del modelo
print(torch_summarize(net))

from torch import nn
from torchviz import make_dot, make_dot_from_trace

# Visualizacion grafica del modelo
make_dot(net(net_input), params=dict(net.named_parameters()))

# Commented out IPython magic to ensure Python compatibility.
# %%time
# p = get_params(OPT_OVER, net, net_input)
# total_loss_final, total_loss_item_final, psrn_final, psrn_masked_final  = optimize(OPTIMIZER, 
#                                                                                    p, 
#                                                                                    closureInpainting, 
#                                                                                    LR, 
#                                                                                    num_iter)

out_np = torch_to_np(net(net_input))
q = plot_image_grid([np.clip(out_np, 0, 1), image_np], factor=13);

#total_loss_item_final, psrn_final, total_loss_final, psrn_masked_final
print("total_loss_item_final: ", "{0:.6f}".format(total_loss_item_final[len(total_loss_item_final)-1]))
print("Relación pico señal / ruido (PSNR): ", "{0:.6f}".format(psrn_final[len(psrn_final)-1]))
print("Relación pico señal / ruido (PSNR) [masked]: ", "{0:.6f}".format(psrn_masked_final[len(psrn_masked_final)-1]))
print("Error cuadrático medio (MSE): ", "{0:.6f}".format(total_loss_final[len(total_loss_final)-1]), "\n")

fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, figsize=(10,10))
mpl.style.use('seaborn')

ax1.set_title('Indice de pérdida total acumulada en cada iteración'.format('seaborn'), color='C0')
ax1.plot(total_loss_item_final, color='C0')

ax2.set_title('Relación pico señal / ruido (PSNR)'.format('seaborn'), color='C1')
ax2.plot(psrn_final, color='C1')

ax3.plot(total_loss_final, color='C2')
ax3.set_title('Error cuadrático medio (MSE)'.format('seaborn'), color='C2')

ax4.set_title('Relación pico señal / ruido (PSNR)[masked]'.format('seaborn'), color='C3')
ax4.plot(psrn_masked_final, color='C3')

plt.tight_layout()
plt.show()
plt.close()

mpl.rcParams.update(inline_rc)